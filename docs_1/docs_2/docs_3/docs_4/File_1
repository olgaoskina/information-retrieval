Apache Spark - высокопроизводительное средство обработки данных, хранящихся в кластере Hadoop. По сравнению с предоставленным в Hadoop механизмом MapReduce, Spark обеспечивает в 100 раз большую производительность при обработке данных в памяти и 10 раз при размещении данных на дисках. Движение может выполняться на узлах кластера Hadoop как с помощью Hadoop YARN, так и в уединенном режиме. Поддерживается обработка данных в хранилищах HDFS, HBase, Cassandra, Hive и любом формате введения Hadoop (InputFormat). Spark может использоваться как в типовых сценариях обработки данных, похожих на MapReduce, так и для реализации специфических методов, таких как потоковая обработка, SQL, интерактивные и аналитические запросы, решения задач машинного обучения и работа с графами. Программы для обработки данных могут создаваться на языках Scala, Java и Python. Spark после пребывания в инкубаторе стал первичным проектом Apache Software Foundation с февраля 2014 года. Из компаний, которые используют Spark, отмечаются Alibaba, Cloudera, Databricks, IBM, Intel и Yahoo.